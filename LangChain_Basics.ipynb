{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0669bf4e-449c-4aa9-825f-6ffce1dd2f3b",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "Installed langchain using console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec93cf-e841-497b-8aff-7860b3d9ad3e",
   "metadata": {},
   "source": [
    "## Setup with HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e36c51-8b7a-47a6-8ab8-da48fb71d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_keys import HF_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e178cc2-723e-4cdf-ad52-b8d5e04a3262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip -q install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa05f9-4159-4910-af99-6d458beff3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import Hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a0c13c-9c17-43dd-bc4f-6cbe4d01cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HF_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87faae5-e197-432a-9d75-bee5ad5d9325",
   "metadata": {},
   "source": [
    "## Using Hugging Face API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6213451d-30ce-493d-b5be-c7b4e7426ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohai\\AppData\\Local\\Temp\\ipykernel_5864\\3731579961.py:13: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm=HuggingFaceHub(repo_id=repo_id,\n",
      "C:\\Users\\mohai\\OneDrive\\Documents\\Jupyter Notebooks\\LangChain\\LCvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\mohai\\AppData\\Local\\Temp\\ipykernel_5864\\3731579961.py:12: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt,\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\", \"restaurant_name\"])\n",
    "\n",
    "repo_id = \"meta-llama/Llama-3.2-3B-Instruct\" # good\n",
    "model = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=HuggingFaceHub(repo_id=repo_id, \n",
    "                                        model_kwargs={\"temperature\":0.9, \n",
    "                                                      \"max_length\":500}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd83c5-158f-4f94-b728-93df4dd093ce",
   "metadata": {},
   "source": [
    "## Random Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3106bc-faf0-45cf-beaa-756885c960b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohai\\AppData\\Local\\Temp\\ipykernel_5864\\675772884.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm_chain.run(question))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of England?\n",
      "\n",
      "Answer:  England has no capital city, it is part of the United Kingdom, and the capital of the United Kingdom is London.\n",
      "\n",
      "However, the capital of England is specifically a topic of debate. \n",
      "\n",
      "Historically, England had several cities that served as its capital, such as London, Winchester, and Stamford. London has been the dominant city for England's capital since the 11th century. Despite this, the UK is a unitary state, and its capital is London, which is also one of the\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the capital of England?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3a3560-70ff-43d3-976d-5a0f08b295fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      "\n",
      "Explain Logarithm?\n",
      "     \n",
      "\n",
      "\n",
      "Answer:  A logarithm is the inverse of an exponential function. In simpler terms, it is the power to which a base number is raised to get a given value. For example, if we have the equation 2^3 = 8, then the logarithm of 8 with base 2 is 3.\n",
      "\n",
      "\n",
      "Here's a more detailed explanation of logarithms:\n",
      "\n",
      " Definition:\n",
      "\n",
      "      A logarithm is a function that takes a positive real number as input and returns the exponent to which a fixed base is\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "\n",
    "Explain Logarithm?\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a79c90-590b-4ec3-ade3-d94f8d062768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Tell me a joke\n",
      "     \n",
      "\n",
      "\n",
      "Answer:  Here's one: \n",
      "\n",
      "  What do you call a fake noodle? \n",
      "\n",
      "  An impasta. \n",
      "\n",
      "  Hope you enjoyed that one! If you want to hear another, let me know!\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\" Tell me a joke\n",
    "     \n",
    "\"\"\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a364e-d096-45a6-b929-837cd89e77c2",
   "metadata": {},
   "source": [
    "## Translation Task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c281c379-50a4-4bb0-80f5-5601e58020f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, SystemMessage\n\u001b[0;32m      3\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     SystemMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslate the following from English into Italian\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi!\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m ]\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(messages)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# question = \"\"\"Translate the following content from English to Italian\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Content: HI! \"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(llm_chain.run(question))\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "\n",
    "model.invoke(messages)\n",
    "# question = \"\"\"Translate the following content from English to Italian\n",
    "# Content: HI! \"\"\"\n",
    "\n",
    "# print(llm_chain.run(question))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74540a78-3cdb-4404-a936-874c072003be",
   "metadata": {},
   "source": [
    "## Sequential Chains \n",
    "\n",
    "Task: Creating a restaurant app  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f96fbb-06a2-4e5f-9f06-f199b00046e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCenv",
   "language": "python",
   "name": "lcenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
